  0%|                                                                                                    | 0/1000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/main.py", line 186, in <module>
    main()
  File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/main.py", line 181, in main
    trainer.train()
  File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/transformers/trainer.py", line 2240, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/transformers/trainer.py", line 3739, in training_step
    inputs = self._prepare_inputs(inputs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/trl/extras/profiling.py", line 87, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/trl/trainer/grpo_trainer.py", line 899, in _prepare_inputs
    accumulated_local_batch = self._generate_and_score_completions(accumulated_local_batch)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/trainers/grpo_env_trainer.py", line 328, in _generate_and_score_completions
    env_result = self.env.generate(
                 ^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/envs/multiturn_env.py", line 236, in generate
    states = self.step(states, llm, custom_sp)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/envs/multiturn_env.py", line 115, in step
    llm_responses = llm.chat(
                    ^^^^^^^^^
  File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/inference/vllm_client.py", line 211, in chat
    raise Exception(f"Request failed: {response.status_code}, {response.text}")
Exception: Request failed: 422, {"detail":[{"type":"string_type","loc":["body","messages",0,0,"content"],"msg":"Input should be a valid string","input":[{"type":"text","text":"Your goal is to accurately provide a coordinate point based on the user’s description and the initial image they supplied. \nYou may use the crop tool to help you analyze and hone in on the target coordinate by placing the tool call inside <crop>...</crop> tags; \neach time you call the crop tool, I will return the resulting cropped image to you. \nIn the end, you must place your selected coordinate inside <answer>...</answer> tags.\n\nThe crop function is used like this: \n\ncrop(\n    top_left: Tuple[int, int],\n    bottom_right: Tuple[int, int]\n) -> Tuple[bytes, Tuple[int, int]]:\n    \"\"\"\n    crop a rectangular region from an image.\n    Args:\n        top_left (Tuple[int, int]): The top-left corner of the cropping rectangle (x1, y1).\n        bottom_right (Tuple[int, int]): The bottom-right corner of the cropping rectangle (x2, y2).\n    Returns:\n        The cropped image.\n    \"\"\"\n\nand here is an example of its use: \n\nUser: [ImageDisplayed] Could you identify the location of the “Close” button in this interface?\n\nAssistant: I’d like to zoom in on the menu icon at the top-left corner to get a clearer view.  \n<crop>crop((10, 20), (110, 100))</crop>\n\nUser: [ImageDisplayed]  # (cropped image returned)\n\nAssistant: In this cropped image, I can see the approximate position of the “Close” button—it sits near the center of the region, slightly toward the lower-right. Converting back to the original image, it’s approximately at (45, 60).  \n<answer>(45, 60)</answer>\n\nPlease note:\n1. You may call the crop tool multiple times if needed.\n2. Each crop is always taken relative to the initial image, not to any previously cropped image.\n3. Your final coordinate must also be given relative to the initial image.\n4. The <answer>...</answer> tags should contain only your final coordinate.\nNow please help me to identify the coordinate of the following element : \nRegister your interest now button"},{"type":"image_url","image_url":{"url":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABQAAAATECAYAAAA06qjhAAEAAElEQVR4nOzdd3xUZb4G8Oec6S29N0LvXaqAoIAFpFiwoujadi2rq7uWVbGta19d9aqra69rw4piAVG6iPROSO9tej3n/jHJyQypExISwvP9XO5Ozpzym8nMmDx53/cnAJDRhTYMGNGVlyfqFqr9fpxxaFdXl0FEREREREREPZC6qwsQBaGrSyDqcnwfEBEREREREVFnEbu6ACIiIiIiIiIiIuo8DACJiIiIiIiIiIh6MAaAREREREREREREPRgDQCIiIiIiIiIioh6MASAREREREREREVEPxgCQiIiIiIiIiIioB2MASERERERERERE1IMxACQiIiIiIiIiIurBGAASERERERERERH1YAwAiYiIiIiIiIiIejAGgERERERERERERD2YuqsLIKKjk6hWo8rvR6CrCyEiIiIioh5DEARYLBY4HA4EAvxtI5ROp4PZbG738bIsw2q1wu/3d2BVgEVUIVWjOapzFPt8sEn8fvdEDACJjlMqAM9m9ME4kwUOKYDtLid+dznwm9OOrS4HpK4ukIiIiIiIjkvR0dGYNWsW4uLi4HA48P3336O0tPSY1pCeno6pU6ciKiqq3eeQZRmVlZX48ccfUVNT0yF1DRo0CFOmTIEoHt2ESq/XixUrVqCoqKhD6poTFYu/p2RAIxxlXZKEB0vy8Y2tpkPqui0pDefGJEAtCEd1Ho8k4bnyYrxfU9EhdY0zmvH35Ayka3XtPocsyzjkdePe4jzs87g7pK7OxCnARMep0ywxGGeyoMLvgwBgosmC6xJS8J+sfliaktnV5RERERER0XEoPT0dCxYsQFxcHADAZDJh7ty5GDBgwDGt45RTTjmq8A8IjmJMSEjApEmTOqgqYPz48Ucd/gGAVqvFSSed1AEVBd2UmHrU4R8AaEURNyWldUBFQed1QPgHADpRxIKY+A6oKOjelMyjCv+A4Ourr86AvyVndFBVnYsjAImOUxfGJgAA7irKxTaXA/10Bow0mHB9YgpmWmKwtCS/iyskIiIiIqLjyZAhQzB58uRGAZdKpcL06dMRExODTZs2QZblTq+lqSm2kiTB7XbDaDRGdC6LxdJRZUGv13fLc8Wpj27qb9i5VB0XFalCwj9ZllHm9yFerWlXKKg++hxRkaLRNrndGvCj3O+DXwYkyBAACBCgFgSkaDQwiarG5+rA574zcQQg0XFoqN6I4QYT9rtd2OJyIABgr8eF/9VUQJIBHyL/D/If/vAH2O12yLKMm2++OeLj58yZg7Vr16KmpgYVFRVYuXIlZsyY0Wi/AQMG4Msvv0R1dTVqa2vx4YcfIiUlpdF+ZrMZL774IoqLi+F0OrF27VpMmDAh4rqA4Bodhw4dgizL2LNnT6P7hwwZgmXLlqG4uBh2ux1bt27Ftdde22i/mJgYvPTSSyguLobH48HOnTtx2WWXtbmOp59+GrIsN/nPbrdHvB8A7Nixo8n9fv/992brGDJkCHw+H2RZxosvvtjm+omIiIioZxIEASeffHLY1Nbc3Fy8+eab2LFjh7LfqFGjMGvWLGiOcp25SEiShI0bN+Kzzz7Da6+9hnfeeQdVVVXH7Po9SZnPhweK83DWwZ2YvG8bzjywE5ce3ndMru2XZVybfxBzD+3GhYf3oqaD1z88Wl/UVmH+od04/cAuXJd/EH8pzMHthYdxa+Fh3FRwCJfl7sOM/TtwYc5erLFbw44V0IHJZCfiCECi49BFdaP//nfE+gcqACZRRJHP2+ZzxcXF4eWXX8Y555zT7npmzJiBzz//HKIo4uuvv4bRaMT06dMxefJkTJgwQQmjjEYjvv/+e2RmZqKwsBBarRbnnXcesrOzMX78+LC/JL7++us499xzYbVaUVJS
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/main.py", line 186, in <module>
[rank0]:     main()
[rank0]:   File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/main.py", line 181, in main
[rank0]:     trainer.train()
[rank0]:   File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/transformers/trainer.py", line 2240, in train
[rank0]:     return inner_training_loop(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/transformers/trainer.py", line 3739, in training_step
[rank0]:     inputs = self._prepare_inputs(inputs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/trl/extras/profiling.py", line 87, in wrapper
[rank0]:     return func(self, *args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/miniconda3/envs/agenttrain/lib/python3.12/site-packages/trl/trainer/grpo_trainer.py", line 899, in _prepare_inputs
[rank0]:     accumulated_local_batch = self._generate_and_score_completions(accumulated_local_batch)
[rank0]:                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/trainers/grpo_env_trainer.py", line 328, in _generate_and_score_completions
[rank0]:     env_result = self.env.generate(
[rank0]:                  ^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/envs/multiturn_env.py", line 236, in generate
[rank0]:     states = self.step(states, llm, custom_sp)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/envs/multiturn_env.py", line 115, in step
[rank0]:     llm_responses = llm.chat(
[rank0]:                     ^^^^^^^^^
[rank0]:   File "/mnt/data1/home/lei00126/AgentTrainer/agenttrain/inference/vllm_client.py", line 211, in chat
[rank0]:     raise Exception(f"Request failed: {response.status_code}, {response.text}")
[rank0]: Exception: Request failed: 422, {"detail":[{"type":"string_type","loc":["body","messages",0,0,"content"],"msg":"Input should be a valid string","input":[{"type":"text","text":"Your goal is to accurately provide a coordinate point based on the user’s description and the initial image they supplied. \nYou may use the crop tool to help you analyze and hone in on the target coordinate by placing the tool call inside <crop>...</crop> tags; \neach time you call the crop tool, I will return the resulting cropped image to you. \nIn the end, you must place your selected coordinate inside <answer>...</answer> tags.\n\nThe crop function is used like this: \n\ncrop(\n    top_left: Tuple[int, int],\n    bottom_right: Tuple[int, int]\n) -> Tuple[bytes, Tuple[int, int]]:\n    \"\"\"\n    crop a rectangular region from an image.\n    Args:\n        top_left (Tuple[int, int]): The top-left corner of the cropping rectangle (x1, y1).\n        bottom_right (Tuple[int, int]): The bottom-right corner of the cropping rectangle (x2, y2).\n    Returns:\n        The cropped image.\n    \"\"\"\n\nand here is an example of its use: \n\nUser: [ImageDisplayed] Could you identify the location of the “Close” button in this interface?\n\nAssistant: I’d like to zoom in on the menu icon at the top-left corner to get a clearer view.  \n<crop>crop((10, 20), (110, 100))</crop>\n\nUser: [ImageDisplayed]  # (cropped image returned)\n\nAssistant: In this cropped image, I can see the approximate position of the “Close” button—it sits near the center of the region, slightly toward the lower-right. Converting back to the original image, it’s approximately at (45, 60).  \n<answer>(45, 60)</answer>\n\nPlease note:\n1. You may call the crop tool multiple times if needed.\n2. Each crop is always taken relative to the initial image, not to any previously cropped image.\n3. Your final coordinate must also be given relative to the initial image.\n4. The <answer>...</answer> tags should contain only your final coordinate.\nNow please help me to identify the coordinate of the following element : \nRegister your interest now button"},{"type":"image_url","image_url":{"url":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABQAAAATECAYAAAA06qjhAAEAAElEQVR4nOzdd3xUZb4G8Oec6S29N0LvXaqAoIAFpFiwoujadi2rq7uWVbGta19d9aqra69rw4piAVG6iPROSO9tej3n/jHJyQypExISwvP9XO5Ozpzym8nMmDx53/cnAJDRhTYMGNGVlyfqFqr9fpxxaFdXl0FEREREREREPZC6qwsQBaGrSyDqcnwfEBEREREREVFnEbu6ACIiIiIiIiIiIuo8DACJiIiIiIiIiIh6MAaAREREREREREREPRgDQCIiIiIiIiIioh6MASAREREREREREVEPxgCQiIiIiIiIiIioB2MASERERERERERE1IMxACQiIiIiIiIiIurBGAASERERERERERH1YAwAiYiIiIiIiIiIejAGgERERERERERERD2YuqsLIKKjk6hWo8rvR6CrCyEiIiIioh5DEARYLBY4HA4EAvxtI5ROp4PZbG738bIsw2q1wu/3d2BVgEVUIVWjOapzFPt8sEn8fvdEDACJjlMqAM9m9ME4kwUOKYDtLid+dznwm9OOrS4HpK4ukIiIiIiIjkvR0dGYNWsW4uLi4HA48P3336O0tPSY1pCeno6pU6ciKiqq3eeQZRmVlZX48ccfUVNT0yF1DRo0CFOmTIEoHt2ESq/XixUrVqCoqKhD6poTFYu/p2RAIxxlXZKEB0vy8Y2tpkPqui0pDefGJEAtCEd1Ho8k4bnyYrxfU9EhdY0zmvH35Ayka3XtPocsyzjkdePe4jzs87g7pK7OxCnARMep0ywxGGeyoMLvgwBgosmC6xJS8J+sfliaktnV5RERERER0XEoPT0dCxYsQFxcHADAZDJh7ty5GDBgwDGt45RTTjmq8A8IjmJMSEjApEmTOqgqYPz48Ucd/gGAVqvFSSed1AEVBd2UmHrU4R8AaEURNyWldUBFQed1QPgHADpRxIKY+A6oKOjelMyjCv+A4Ourr86AvyVndFBVnYsjAImOUxfGJgAA7irKxTaXA/10Bow0mHB9YgpmWmKwtCS/iyskIiIiIqLjyZAhQzB58uRGAZdKpcL06dMRExODTZs2QZblTq+lqSm2kiTB7XbDaDRGdC6LxdJRZUGv13fLc8Wpj27qb9i5VB0XFalCwj9ZllHm9yFerWlXKKg++hxRkaLRNrndGvCj3O+DXwYkyBAACBCgFgSkaDQwiarG5+rA574zcQQg0XFoqN6I4QYT9rtd2OJyIABgr8eF/9VUQJIBHyL/D/If/vAH2O12yLKMm2++OeLj58yZg7Vr16KmpgYVFRVYuXIlZsyY0Wi/AQMG4Msvv0R1dTVqa2vx4YcfIiUlpdF+ZrMZL774IoqLi+F0OrF27VpMmDAh4rqA4Bodhw4dgizL2LNnT6P7hwwZgmXLlqG4uBh2ux1bt27Ftdde22i/mJgYvPTSSyguLobH48HOnTtx2WWXtbmOp59+GrIsN/nPbrdHvB8A7Nixo8n9fv/992brGDJkCHw+H2RZxosvvtjm+omIiIioZxIEASeffHLY1Nbc3Fy8+eab2LFjh7LfqFGjMGvWLGiOcp25SEiShI0bN+Kzzz7Da6+9hnfeeQdVVVXH7Po9SZnPhweK83DWwZ2YvG8bzjywE5ce3ndMru2XZVybfxBzD+3GhYf3oqaD1z88Wl/UVmH+od04/cAuXJd/EH8pzMHthYdxa+Fh3FRwCJfl7sOM/TtwYc5erLFbw44V0IHJZCfiCECi49BFdaP//nfE+gcqACZRRJHP2+ZzxcXF4eWXX8Y555zT7npmzJiBzz//HKIo4uuvv4bRaMT06dMxefJkTJgwQQmjjEYjvv/+e2RmZqKwsBBarRbnnXcesrOzMX78+LC/JL7++us499x
